{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "from flopy.utils.gridintersect import GridIntersect\n",
    "#import pyemu\n",
    "\n",
    "from shapely.geometry import Polygon, Point\n",
    "import shapefile\n",
    "from shapely.prepared import prep\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_pth = os.path.join('..', 'bins', 'win') if 'nt' in os.name else os.path.join('..', 'bins', 'linux') # Binaries\n",
    "shapefile_pth = os.path.join('..', 'data', 'raw_data', 'shapefiles')\n",
    "observations_pth = os.path.join('..', 'data', 'observations') # Measured data (field obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_model_ws = os.path.join('..', 'temp_flopy_lumprem')\n",
    "os.listdir(org_model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_ws = os.path.join('..', 'temp_ml_param') # Safe to delete\n",
    "if os.path.exists(tmp_model_ws):\n",
    "    shutil.rmtree(tmp_model_ws)\n",
    "shutil.copytree(org_model_ws,tmp_model_ws)\n",
    "os.listdir(tmp_model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_name = 'hagfors_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(ml_name, 'mf6', os.path.join(bins_pth, 'mf6'), tmp_model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all data external so that PEST can adjust parameter values during history matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.set_all_data_external(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwf = sim.get_model(ml_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "plt.ticklabel_format(axis='both', style='plain', useOffset=False) #Show coordinates\n",
    "ax.set_title('Model grid', fontsize=18)\n",
    "\n",
    "mapview = flopy.plot.PlotMapView(gwf, layer=0)\n",
    "linecollection = mapview.plot_grid(lw=0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pilot points\n",
    "3D-pilot points will be generated for the following areal properties:\n",
    "- SY & SS (perhaps SS could be skipped?)\n",
    "- Porosity and possibly diffusion/dispersion and any other parameter needed to represent transport\n",
    "- Kh and Kz\n",
    "\n",
    "In addition, pilot points will be generated along the following linear features:\n",
    "- Streambed hydraulic conductivity along Creek Örbäcken (SFR package)\n",
    "- GHB conductance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D pilot points\n",
    "Because we want to do a data-worth analysis, we should consider the total amount of pilot points to be employed to find a suitable compromise between adjustable parameters and model run-time.\n",
    "\n",
    "For this reason, we will create different sets of pilot points for each parameter type (in order to not use an exessive amount of pps).\n",
    "\n",
    "Sy, SS and possibly porosity (along with other parameters that govern transport) could be parameterized using a coarser pp-spacing, so let's start with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, before we start, let's import the observation locations, so that we can see how the pilot points will be located in relation to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_obs = pd.read_excel(os.path.join(observations_pth, 'obs_flow_and_stage.xlsx'))\n",
    "head_obs = pd.read_excel(os.path.join(observations_pth, 'obs_head_per_layer.xlsx')).drop_duplicates(subset=['POINT_X', 'POINT_Y'])\n",
    "head_obs['TYPE'] = 'HEAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_points = pd.concat([head_obs, sfr_obs])\n",
    "display(obs_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coarse 3D pilot points\n",
    "Let's create the coarse pilot point distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_boundary = shapefile.Reader(os.path.join(shapefile_pth, 'model_boundary.shp')) # Model boundary shapefile\n",
    "mlb_shape = np.array(np.rint(ml_boundary.shapeRecords()[0].shape.points)) # Model boundary array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a shapely polygon of the model boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_shapely = Polygon(mlb_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create prepared polygon of the model boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlb_shapely_prep = prep(mlb_shapely.buffer(50)) buffer cause an issue because the grid can't be sampled outside the model boundary\n",
    "mlb_shapely_prep = prep(mlb_shapely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a rectangular mesh of points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax, ymin, ymax = 426900, 427700, 6654650, 6655350 # These are the same coordinates used to construct the base-grid\n",
    "resolution = 30 # Equal space (in meters) between pilot points\n",
    "basepoints = []\n",
    "for lat in np.arange(xmin, xmax, resolution):\n",
    "    for lon in np.arange(ymin, ymax, resolution):\n",
    "        basepoints.append(Point((round(lat,4), round(lon,4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the shapely `contains` (point-in-polygon method) to select points inside the model boundary (increase the number of pps once workflow is confirmed working):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepip = [] # Basepoints in polygon\n",
    "for point in basepoints:\n",
    "    if mlb_shapely_prep.contains(point):\n",
    "        basepip.append(point)\n",
    "print(f'Number of points per layer: {len(basepip)}') # We need to extend it into three dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the position of the pilot points on top of the model grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "plt.ticklabel_format(axis='both', style='plain', useOffset=False) #Show coordinates\n",
    "ax.set_title('Coarse pilot point locations', fontsize=18)\n",
    "\n",
    "mapview = flopy.plot.PlotMapView(gwf, layer=0)\n",
    "linecollection = mapview.plot_grid(lw=0.25)\n",
    "\n",
    "x = np.array([i.coords[0] for i in basepip])[:,0]\n",
    "y = np.array([i.coords[0] for i in basepip])[:,1]\n",
    "plt.scatter(x, y, s=5, c='black', alpha=0.5, label='PILOT POINT')\n",
    "\n",
    "for category in obs_points['TYPE'].unique():\n",
    "    x = obs_points.loc[obs_points['TYPE'] == category]['POINT_X']\n",
    "    y = obs_points.loc[obs_points['TYPE'] == category]['POINT_Y']\n",
    "    ax.scatter(x, y, s=20, alpha=0.6, label=category)\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These points now need to be assigned a z-value, since we are going to use 3D-pilot points. To do this, we will need to intersect the model grid and retrieve the z-values of each layer, so that a copy of these pps can be positioned in each of the three layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = GridIntersect(gwf.modelgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect = {\n",
    "    'cellids': [],\n",
    "    'vertices': [],\n",
    "    'ixshapes': [],\n",
    "}\n",
    "for point in basepip:\n",
    "    pp_intersect['cellids'].append(ix.intersect(point).cellids[0])\n",
    "    pp_intersect['vertices'].append(ix.intersect(point).vertices[0])\n",
    "    pp_intersect['ixshapes'].append(ix.intersect(point).ixshapes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect = pd.DataFrame(pp_intersect)\n",
    "display(pp_intersect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the order is respected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.coords[0] for i in basepip][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the cellids to sample pilot point elevations (**this takes about 2 minutes on my laptop for 295 cells** and could/should probably be speed up somehow - considering it has to be done for top, botm1, botm2 and botm3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_elevation(elevation_array, index_array):\n",
    "    '''\n",
    "    returns list of elevations\n",
    "    '''\n",
    "    \n",
    "    elevations = list(elevation_array)\n",
    "    indices = list(index_array)\n",
    "    \n",
    "    return [elevation_array[i] for i in index_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect['top'] = get_grid_elevation(elevation_array = gwf.modelgrid.top, index_array=pp_intersect['cellids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect['botm_1'] = get_grid_elevation(gwf.modelgrid.botm[0], pp_intersect['cellids'])\n",
    "pp_intersect['botm_2'] = get_grid_elevation(gwf.modelgrid.botm[1], pp_intersect['cellids'])\n",
    "pp_intersect['botm_3'] = get_grid_elevation(gwf.modelgrid.botm[2], pp_intersect['cellids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pps in-between the layer boundaries (i.e. vertically centered in the cells):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect['pps_l1'] = (pp_intersect['top'] + pp_intersect['botm_1']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect['pps_l2'] = (pp_intersect['botm_1'] + pp_intersect['botm_2']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect['pps_l3'] = (pp_intersect['botm_2'] + pp_intersect['botm_3']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pp_intersect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add x, y and clean up df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect['x'] = np.array([i.coords[0] for i in basepip])[:,0]\n",
    "pp_intersect['y'] = np.array([i.coords[0] for i in basepip])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect = pp_intersect[['x', 'y', 'pps_l1', 'pps_l2', 'pps_l3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "fig = pyplot.figure(figsize=(6,6))\n",
    "ax = Axes3D(fig)\n",
    "ax.set_box_aspect([2,2,1])\n",
    "\n",
    "x, y = pp_intersect.x.values, pp_intersect.y.values\n",
    "\n",
    "ax.scatter(x, y, pp_intersect.pps_l1.values)\n",
    "ax.scatter(x, y, pp_intersect.pps_l2.values)\n",
    "ax.scatter(x, y, pp_intersect.pps_l3.values)\n",
    "plt.title('pps in 3d-space')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe into a 3d pilot point file format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_coarse3d = pd.melt(pp_intersect, id_vars=['x', 'y'], value_vars=['pps_l1', 'pps_l2', 'pps_l3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "fig = pyplot.figure(figsize=(6,6))\n",
    "ax = Axes3D(fig)\n",
    "ax.set_box_aspect([2,2,1])\n",
    "\n",
    "x, y = pp_coarse3d.x.values, pp_coarse3d.y.values\n",
    "\n",
    "ax.scatter(x, y, pp_coarse3d.value.values)\n",
    "plt.title('pps in 3d-space')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_coarse3d['name'] = [f'ppc{i:04d}' for i in pp_coarse3d.index.values] # ppc = pilot point coarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_coarse3d[['zone','val']] = 1, 1\n",
    "pp_coarse3d['z'] = pp_coarse3d['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_coarse3d['layer'] = [int(i[-1]) for i in pp_coarse3d['variable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_coarse3d = pp_coarse3d[['name', 'x', 'y', 'z', 'zone', 'val', 'layer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pp_coarse3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumpyrem import run\n",
    "#MKPPSTAT\n",
    "# mkppstat requires no headers in ppoint file ...sigh...\n",
    "pp_coarse3d.to_csv(os.path.join(tmp_model_ws, 'mkppoints3d_coarse.dat'),\n",
    "                       header=None, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for MKPPSTAT\n",
    "# A (a)-factor of 1.5 is often reasonable. from tutorial \n",
    "npoints_h, npoints_v = 10, 10 # np-horizontal, np-vertical\n",
    "a_h, a_v = 1.2, 1.2 # a-horizontal, a-vertical\n",
    "# run MKPPSTAT\n",
    "run.run_process(\n",
    "    'mkppstat3d',\n",
    "    path=tmp_model_ws,\n",
    "    commands=['mkppoints3d_coarse.dat', npoints_h, a_h, npoints_v, a_v, 'ppstat3d_coarse.dat']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run PPCOV3D_SVA - pilot point covariance 3d - spatially varying anisotropy\n",
    "run.run_process(\n",
    "    'ppcov3d_sva',\n",
    "    path=tmp_model_ws,\n",
    "    commands=['ppstat3d_coarse.dat', 'y', 1, 'x',  'cov3d_coarse.mat', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cov mat file with Pyemu for further processing\n",
    "import pyemu\n",
    "covmat_coarse = pyemu.Cov.from_ascii(os.path.join(tmp_model_ws, \"cov3d_coarse.mat\"))\n",
    "\n",
    "# This covaraince matrix can now be used as the base for all pilot point parameters. \n",
    "# Note that in this case the variance is 1, so it is easy to scale to a parameters prior varaince\n",
    "# Depending on how you setup the scrpt, variance can be assigned at various stages (i.e. when running PPCOV_SVA, or by manipulating the matrix later)\n",
    "# Note that parameter names (headers and row names) come from the parameter name sin the ppoint file. These can have a prefix added by PPCOV_SVA, or changed in the dataframe. The latter is more versatile.\n",
    "covmat_coarse.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this matrix only used during regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=100)\n",
    "plt.imshow(covmat_coarse.as_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_coarse3d[['kh', 'kv', 'sy', 'ss']] = 86.4, 8.64, 0.2, 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_coarse3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_coarse3d.to_csv(os.path.join(tmp_model_ws, 'pp3d_coarse.dat'),\n",
    "                       header=None, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup parameterization for 3D elements (K, storage, porosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_plproc_script(filename, lines):\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate kriging factors (porosity not included yet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_plproc_script(os.path.join(tmp_model_ws, 'plproc1_temp.dat'), [\n",
    "f'''\n",
    "### Read model grid ###\n",
    "cl_mf = read_mf6_grid_specs(file={ml_name}.disv.grb,               &\n",
    "                            dimensions=2,                             &\n",
    "                            slist_layer_idomain=idomain1;  layer=1,   &\n",
    "                            slist_layer_idomain=idomain2;  layer=2,   &\n",
    "                            slist_layer_idomain=idomain3;  layer=3)\n",
    "\n",
    "\n",
    "\n",
    "### Read 3D pilot-points file ###\n",
    "cl_pp = read_list_file(file=pp3d_coarse.dat,               &\n",
    "                       id_type=character,                  &\n",
    "                       dimensions=2,                       &\n",
    "                       slist=zone; col=5,                  &\n",
    "                       slist=lyr; col=7,                   &\n",
    "                       plist=kh_pp; col=8,                 &\n",
    "                       plist=kv_pp; col=9,                 &\n",
    "                       plist=sy_pp; col=10,                &\n",
    "                       plist=ss_pp; col=11)\n",
    "\n",
    "\n",
    "### Calculate kriging factors for each layer ###\n",
    "calc_kriging_factors_auto_2d(                    &\n",
    "           target_clist=cl_mf,                   &\n",
    "           source_clist=cl_pp;select=(lyr==1),   &\n",
    "           file=factors_pp_lyr1.dat)\n",
    "\n",
    "calc_kriging_factors_auto_2d(                    &\n",
    "           target_clist=cl_mf,                   &\n",
    "           source_clist=cl_pp;select=(lyr==2),   &\n",
    "           file=factors_pp_lyr2.dat)\n",
    "\n",
    "calc_kriging_factors_auto_2d(                    &\n",
    "           target_clist=cl_mf,                   &\n",
    "           source_clist=cl_pp;select=(lyr==3),   &\n",
    "           file=factors_pp_lyr3.dat)\n",
    "\n",
    "'''\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run PLPROC\n",
    "run.run_process(\n",
    "    'plproc',\n",
    "    path=tmp_model_ws,\n",
    "    commands=['plproc1_temp.dat']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup parameterization for linear elements (GHBs & SFR)\n",
    "Setup pilot points for linear boundary conditions General Head Boundaries (GHBs) and Creek Örbäcken (SFR), starting with SFR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segfile = pd.read_csv(os.path.join(tmp_model_ws, 'sfr_segfile.dat'), sep='\\t', names=['x', 'y', 'seg'])\n",
    "display(segfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the segments. This should probably be done in a better way and perhaps changed after the first round of history matching to get a better representation of stream reaches. This solution is just to make things work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_divisor(n):\n",
    "    a = 1\n",
    "    for i in range(2, n):\n",
    "        if n % i == 0:\n",
    "            a = i\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nseg = largest_divisor(len(segfile))\n",
    "#nseg = largest_divisor(nseg) # divide again to reduce the amount of pps from 135 to 45 (perhaps a stupid move)\n",
    "print(nseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_per_seg = int(len(segfile) / nseg)\n",
    "print(rows_per_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nseg):\n",
    "    segfile.loc[(i * rows_per_seg):((i + 1) * rows_per_seg), ('seg')] = f's{i + 1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite seglist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segfile.to_csv(\n",
    "    os.path.join(tmp_model_ws, 'sfr_segfile.dat'),\n",
    "    header=None,\n",
    "    index=False,\n",
    "    sep='\\t',\n",
    "    float_format='%.3f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GHB Seglists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghb_seglists = []\n",
    "for filename in os.listdir(tmp_model_ws):\n",
    "    if 'ghb_' in filename and '_segfile.dat' in filename:\n",
    "        ghb_seglists.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghb_seglists_dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in ghb_seglists:\n",
    "    ghb_seglists_dfs[filename.replace('_segfile.dat', '')] = pd.read_csv(\n",
    "        os.path.join(tmp_model_ws, filename),\n",
    "        sep='\\t',\n",
    "        names=['x', 'y', 'seg']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghb_seglists_dfs['ghb_red']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign segment IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ghb_seglists_dfs.items():\n",
    "    print(f'rows in {k}: {len(v[\"seg\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,segfile in ghb_seglists_dfs.items():\n",
    "    nseg = largest_divisor(len(segfile))\n",
    "    rows_per_seg = int(len(segfile) / nseg)\n",
    "    for i in range(nseg):\n",
    "        segfile.loc[(i * rows_per_seg):((i + 1) * rows_per_seg), ('seg')] = f's{i + 1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghb_seglists_dfs['ghb_red']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm still not sure about the implification of segments... for example there are three rows in ghb_orange and ghb_red each. However, ghb_red is about 5 times the size of ghb_orange... Assigning a single segment to all ghbs except yellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghb_seglists_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, segfile in ghb_seglists_dfs.items():\n",
    "    segfile.to_csv(\n",
    "        os.path.join(tmp_model_ws, f'{k}_segfile.dat'),\n",
    "        header=None,\n",
    "        index=False,\n",
    "        sep='\\t',\n",
    "        float_format='%.3f'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_plproc_script(os.path.join(tmp_model_ws, 'plproc_seglist_temp1.dat'), [\n",
    "f'''\n",
    "### Read model grid ###\n",
    "cl_mf = read_mf6_grid_specs(                &\n",
    "    file={ml_name}.disv.grb,                &\n",
    "    dimensions=2,                           &\n",
    "    slist_layer_idomain=idomain1;  layer=1, &\n",
    "    slist_layer_idomain=idomain2;  layer=2, &\n",
    "    slist_layer_idomain=idomain3;  layer=3  &\n",
    "    )\n",
    "\n",
    "\n",
    "### Read Creek Örbäcken SFR seglist file ###\n",
    "sl_sfr = read_segfile(file=\"sfr_segfile.dat\", protocol=table)\n",
    "    \n",
    "### Read GHB seglist files ###\n",
    "sl_ghb_red = read_segfile(file=\"ghb_red_segfile.dat\", protocol=table)\n",
    "sl_ghb_orange = read_segfile(file=\"ghb_orange_segfile.dat\", protocol=table)\n",
    "sl_ghb_yellow = read_segfile(file=\"ghb_yellow_segfile.dat\", protocol=table)\n",
    "sl_ghb_limegreen = read_segfile(file=\"ghb_limegreen_segfile.dat\", protocol=table)\n",
    "sl_ghb_royalblue = read_segfile(file=\"ghb_royalblue_segfile.dat\", protocol=table)\n",
    "sl_ghb_blueviolet = read_segfile(file=\"ghb_blueviolet_segfile.dat\", protocol=table)\n",
    "sl_ghb_magenta = read_segfile(file=\"ghb_magenta_segfile.dat\", protocol=table)\n",
    "\n",
    "\n",
    "### Create clist with sl_sfr as its base ###\n",
    "cl_sfr_pp = create_clist_from_seglist(seglist=sl_sfr, linkage_type=endpoints, dist_thresh=5.0)\n",
    "\n",
    "### Create clist with sl_ghb* as its base ###\n",
    "cl_ghb_red_pp = create_clist_from_seglist(seglist=sl_ghb_red, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_orange_pp = create_clist_from_seglist(seglist=sl_ghb_orange, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_yellow_pp = create_clist_from_seglist(seglist=sl_ghb_yellow, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_limegreen_pp = create_clist_from_seglist(seglist=sl_ghb_limegreen, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_royalblue_pp = create_clist_from_seglist(seglist=sl_ghb_royalblue, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_blueviolet_pp = create_clist_from_seglist(seglist=sl_ghb_blueviolet, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_magenta_pp = create_clist_from_seglist(seglist=sl_ghb_magenta, linkage_type=endpoints, dist_thresh=5.0)\n",
    "\n",
    "\n",
    "### Write reports (pps will be constructed based on theses reports) ###\n",
    "cl_sfr_pp.report_dependent_lists(file='report_sfr_seglist.dat')\n",
    "\n",
    "cl_ghb_red_pp.report_dependent_lists(file='report_ghb_red_seglist.dat')\n",
    "cl_ghb_orange_pp.report_dependent_lists(file='report_ghb_orange_seglist.dat')\n",
    "cl_ghb_yellow_pp.report_dependent_lists(file='report_ghb_yellow_seglist.dat')\n",
    "cl_ghb_limegreen_pp.report_dependent_lists(file='report_ghb_limegreen_seglist.dat')\n",
    "cl_ghb_royalblue_pp.report_dependent_lists(file='report_ghb_royalblue_seglist.dat')\n",
    "cl_ghb_blueviolet_pp.report_dependent_lists(file='report_ghb_blueviolet_seglist.dat')\n",
    "cl_ghb_magenta_pp.report_dependent_lists(file='report_ghb_magenta_seglist.dat')\n",
    "'''\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN PLPROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run PLPROC\n",
    "run.run_process(\n",
    "    'plproc',\n",
    "    path=tmp_model_ws,\n",
    "    commands=['plproc_seglist_temp1.dat']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SEGLIST pilot points from the report files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for writing conductance files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_conductance(filename, conductance):\n",
    "    df = pd.read_csv(os.path.join(tmp_model_ws, filename), skiprows=[0, 1, 2])\n",
    "    \n",
    "    df['ID'] = df.index + 1\n",
    "    df['conductance'] = conductance\n",
    "    df = df[['ID', 'conductance']]\n",
    "    new_filename = filename.replace('report_', '').replace('_seglist.dat', '')\n",
    "    new_filename = new_filename + '_cond.dat'\n",
    "    \n",
    "    print(f'Writing {new_filename}')\n",
    "    df.to_csv(\n",
    "        os.path.join(tmp_model_ws, new_filename),\n",
    "        header=None,\n",
    "        index=False,\n",
    "        sep='\\t',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportfiles = [i for i in os.listdir(tmp_model_ws) if 'report_' in i]\n",
    "display(reportfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in reportfiles:\n",
    "    write_conductance(file, 86.4) # Assigning 86.4 as starting K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate kriging interpolation factors for the SEGLISTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_plproc_script(os.path.join(tmp_model_ws, 'plproc_seglist_temp2.dat'), [\n",
    "f'''\n",
    "### Read model grid ###\n",
    "\n",
    "cl_mf = read_mf6_grid_specs(  &\n",
    "    file={ml_name}.disv.grb,  &\n",
    "    dimensions=3,             & # Note 3D in this case\n",
    "    slist_layernum = layer,   &\n",
    "    slist_idomain = idomain   &\n",
    "    )\n",
    "\n",
    "\n",
    "### Read Creek Örbäcken SFR seglist file ###\n",
    "sl_sfr = read_segfile(file=\"sfr_segfile.dat\", protocol=table)\n",
    "    \n",
    "### Read GHB seglist files ###\n",
    "sl_ghb_red = read_segfile(file=\"ghb_red_segfile.dat\", protocol=table)\n",
    "sl_ghb_orange = read_segfile(file=\"ghb_orange_segfile.dat\", protocol=table)\n",
    "sl_ghb_yellow = read_segfile(file=\"ghb_yellow_segfile.dat\", protocol=table)\n",
    "sl_ghb_limegreen = read_segfile(file=\"ghb_limegreen_segfile.dat\", protocol=table)\n",
    "sl_ghb_royalblue = read_segfile(file=\"ghb_royalblue_segfile.dat\", protocol=table)\n",
    "sl_ghb_blueviolet = read_segfile(file=\"ghb_blueviolet_segfile.dat\", protocol=table)\n",
    "sl_ghb_magenta = read_segfile(file=\"ghb_magenta_segfile.dat\", protocol=table)\n",
    "\n",
    "\n",
    "### Create clist with sl_sfr as its base ###\n",
    "cl_sfr_pp = create_clist_from_seglist(seglist=sl_sfr, linkage_type=endpoints, dist_thresh=5.0)\n",
    "\n",
    "### Create clist with sl_ghb* as its base ###\n",
    "cl_ghb_red_pp = create_clist_from_seglist(seglist=sl_ghb_red, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_orange_pp = create_clist_from_seglist(seglist=sl_ghb_orange, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_yellow_pp = create_clist_from_seglist(seglist=sl_ghb_yellow, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_limegreen_pp = create_clist_from_seglist(seglist=sl_ghb_limegreen, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_royalblue_pp = create_clist_from_seglist(seglist=sl_ghb_royalblue, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_blueviolet_pp = create_clist_from_seglist(seglist=sl_ghb_blueviolet, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_magenta_pp = create_clist_from_seglist(seglist=sl_ghb_magenta, linkage_type=endpoints, dist_thresh=5.0)\n",
    "\n",
    "\n",
    "### Instruct PLPROC to read the *_cond.dat     ###\n",
    "### list file to obtain conductance values at  ###\n",
    "### pilot points by inserting the following    ###\n",
    "### function into the PLPROC script.           ###\n",
    "read_list_file(reference_clist='cl_sfr_pp', file='sfr_cond.dat', plist='pp_sfr_cond';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_red_pp', file='ghb_red_cond.dat', plist='pp_ghb_red_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_orange_pp', file='ghb_orange_cond.dat', plist='pp_ghb_orange_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_yellow_pp', file='ghb_yellow_cond.dat', plist='pp_ghb_yellow_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_limegreen_pp', file='ghb_limegreen_cond.dat', plist='pp_ghb_limegreen_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_royalblue_pp', file='ghb_royalblue_cond.dat', plist='pp_ghb_royalblue_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_blueviolet_pp', file='ghb_blueviolet_cond.dat', plist='pp_ghb_blueviolet_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_magenta_pp', file='ghb_magenta_cond.dat', plist='pp_ghb_magenta_c';column=2)\n",
    "\n",
    "\n",
    "### Instruct PLPROC to build an SLIST of model ###\n",
    "### drain cells to which interpolation must    ###\n",
    "### take place                                 ###\n",
    "sfr_cells = cl_mf.find_cells_in_lists(file={ml_name}.sfr_packagedata.txt, model_type=mf6_disv, &\n",
    "    list_col_start=2, keytext_start='top_of_file', keytext_end='end_of_file')\n",
    "\n",
    "ghb_red_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, model_type=mf6_disv, &\n",
    "    list_col_start=1, keytext_start='top_of_file', keytext_end='2387  ghb_orange')\n",
    "    \n",
    "ghb_orange_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, model_type=mf6_disv, &\n",
    "    list_col_start=1, keytext_start='2387  ghb_red', keytext_end='2792  ghb_yellow')\n",
    "\n",
    "ghb_yellow_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, model_type=mf6_disv, &\n",
    "    list_col_start=1, keytext_start='2800  ghb_orange', keytext_end='2802  ghb_limegreen')\n",
    "\n",
    "ghb_limegreen_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, model_type=mf6_disv, &\n",
    "    list_col_start=1, keytext_start='3090  ghb_yellow', keytext_end='1  ghb_royalblue')\n",
    "\n",
    "ghb_royalblue_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, model_type=mf6_disv, &\n",
    "    list_col_start=1, keytext_start='3057  ghb_limegreen', keytext_end='1  ghb_blueviolet')\n",
    "\n",
    "ghb_blueviolet_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, model_type=mf6_disv, &\n",
    "    list_col_start=1, keytext_start='2802  ghb_royalblue', keytext_end='316  ghb_magenta')\n",
    "\n",
    "ghb_magenta_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, model_type=mf6_disv, &\n",
    "    list_col_start=1, keytext_start='316  ghb_blueviolet', keytext_end='end_of_file')\n",
    "\n",
    "### Calculate interpolation factors to these   ###\n",
    "### model cells through linear interpolation   ###\n",
    "### along the segments (only run once)         ###\n",
    "calc_linear_interp_factors(                               &\n",
    "    source_clist=cl_sfr_pp,                               &\n",
    "    target_clist=cl_mf;select=(sfr_cells.ne.0),           &\n",
    "    file=\"factors_sfr_cells.dat\",                         &\n",
    "    search_radius=50                                      &\n",
    "    )\n",
    "\n",
    "calc_linear_interp_factors(                               &\n",
    "    source_clist=cl_ghb_red_pp,                           &\n",
    "    target_clist=cl_mf;select=(ghb_red_cells.ne.0),       &\n",
    "    file=\"factors_ghb_red_cells.dat\",                     &\n",
    "    search_radius=50                                      &\n",
    "    )\n",
    "\n",
    "calc_linear_interp_factors(                               &\n",
    "    source_clist=cl_ghb_orange_pp,                        &\n",
    "    target_clist=cl_mf;select=(ghb_orange_cells.ne.0),    &\n",
    "    file=\"factors_ghb_orange_cells.dat\",                  &\n",
    "    search_radius=50                                      &\n",
    "    )\n",
    "\n",
    "calc_linear_interp_factors(                               &\n",
    "    source_clist=cl_ghb_yellow_pp,                        &\n",
    "    target_clist=cl_mf;select=(ghb_yellow_cells.ne.0),    &\n",
    "    file=\"factors_ghb_yellow_cells.dat\",                  &\n",
    "    search_radius=50                                      &\n",
    "    )\n",
    "\n",
    "calc_linear_interp_factors(                                &\n",
    "    source_clist=cl_ghb_limegreen_pp,                      &\n",
    "    target_clist=cl_mf;select=(ghb_limegreen_cells.ne.0),  &\n",
    "    file=\"factors_ghb_limegreen_cells.dat\",                &\n",
    "    search_radius=50                                       &\n",
    "    )\n",
    "\n",
    "calc_linear_interp_factors(                                &\n",
    "    source_clist=cl_ghb_royalblue_pp,                      &\n",
    "    target_clist=cl_mf;select=(ghb_royalblue_cells.ne.0),  &\n",
    "    file=\"factors_ghb_royalblue_cells.dat\",                &\n",
    "    search_radius=50                                       &\n",
    "    )\n",
    "\n",
    "calc_linear_interp_factors(                                &\n",
    "    source_clist=cl_ghb_blueviolet_pp,                     &\n",
    "    target_clist=cl_mf;select=(ghb_blueviolet_cells.ne.0), &\n",
    "    file=\"factors_ghb_blueviolet_cells.dat\",               &\n",
    "    search_radius=50                                       &\n",
    "    )\n",
    "\n",
    "calc_linear_interp_factors(                                &\n",
    "    source_clist=cl_ghb_magenta_pp,                        &\n",
    "    target_clist=cl_mf;select=(ghb_magenta_cells.ne.0),    &\n",
    "    file=\"factors_ghb_magenta_cells.dat\",                  &\n",
    "    search_radius=50                                       &\n",
    "    )\n",
    "'''\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run PLPROC\n",
    "run.run_process(\n",
    "    'plproc',\n",
    "    path=tmp_model_ws,\n",
    "    commands=['plproc_seglist_temp2.dat']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(tmp_model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final PLPROC script for use in history-matching\n",
    "(transport pertinent parameters to be added once worflow is OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write generic template\n",
    "with open(os.path.join(tmp_model_ws, 'gen_mf_array.tpl'), 'a') as f:\n",
    "    f.write('$#p prop_mf.write_in_sequence(format=\"(1x,1pg18.11)\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disv = gwf.get_package('disv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpl = disv.ncpl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_plproc_script(os.path.join(tmp_model_ws, 'plproc1.dat'), [\n",
    "f'''\n",
    "### Read model grid ###\n",
    "cl_mf = read_mf6_grid_specs(file={ml_name}.disv.grb,                  &\n",
    "                            dimensions=2,                             &\n",
    "                            slist_layer_idomain=idomain1;  layer=1,   &\n",
    "                            slist_layer_idomain=idomain2;  layer=2,   &\n",
    "                            slist_layer_idomain=idomain3;  layer=3)\n",
    "\n",
    "###### --- 3D pps\n",
    "\n",
    "\n",
    "### Read 3D pilot-points file ###\n",
    "cl_pp = read_list_file(file=pp3d_coarse.dat,               &\n",
    "                       id_type=character,                  &\n",
    "                       dimensions=2,                       &\n",
    "                       slist=zone; col=5,                  &\n",
    "                       slist=lyr; col=7,                   &\n",
    "                       plist=kh_pp; col=8,                 &\n",
    "                       plist=kv_pp; col=9,                 &\n",
    "                       plist=sy_pp; col=10,                &\n",
    "                       plist=ss_pp; col=11)\n",
    "\n",
    "\n",
    "### Write  ###\n",
    "prop_mf=new_plist(reference_clist=cl_mf,value=1.0)\n",
    "\n",
    "\n",
    "###   Horizontal K   ###\n",
    "### Write kh layer 1 ###\n",
    "prop_mf=86.4\n",
    "prop_mf=kh_pp.krige_using_file(file='factors_pp_lyr1.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.npf_k_layer1.txt)\n",
    "\n",
    "### Write kh layer 2 ###\n",
    "prop_mf=86.4\n",
    "prop_mf=kh_pp.krige_using_file(file='factors_pp_lyr2.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.npf_k_layer2.txt)\n",
    "\n",
    "### Write kh layer 3 ###\n",
    "prop_mf=86.4\n",
    "prop_mf=kh_pp.krige_using_file(file='factors_pp_lyr3.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.npf_k_layer3.txt)\n",
    "\n",
    "\n",
    "###    Vertical K    ###\n",
    "### Write kv layer 1 ###\n",
    "prop_mf=8.64\n",
    "prop_mf=kv_pp.krige_using_file(file='factors_pp_lyr1.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.npf_k33_layer1.txt)\n",
    "\n",
    "### Write kv layer 2 ###\n",
    "prop_mf=8.64\n",
    "prop_mf=kv_pp.krige_using_file(file='factors_pp_lyr2.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.npf_k33_layer2.txt)\n",
    "\n",
    "### Write kv layer 3 ###\n",
    "prop_mf=8.64\n",
    "prop_mf=kv_pp.krige_using_file(file='factors_pp_lyr3.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.npf_k33_layer3.txt)\n",
    "\n",
    "\n",
    "\n",
    "###      STORAGE     ###\n",
    "###        sy        ###\n",
    "### Write sy layer 1 ###\n",
    "prop_mf=0.2\n",
    "prop_mf=sy_pp.krige_using_file(file='factors_pp_lyr1.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.sto_sy_layer1.txt)\n",
    "\n",
    "\n",
    "###        ss        ###\n",
    "### Write ss layer 2 ###\n",
    "prop_mf=0.000001\n",
    "prop_mf=ss_pp.krige_using_file(file='factors_pp_lyr2.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.sto_ss_layer2.txt)\n",
    "\n",
    "### Write ss layer 3 ###\n",
    "prop_mf=0.000001\n",
    "prop_mf=ss_pp.krige_using_file(file='factors_pp_lyr3.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array.tpl, model_input_file={ml_name}.sto_ss_layer3.txt)\n",
    "\n",
    "\n",
    "\n",
    "###### --- SFR SEGLISTS\n",
    "\n",
    "### Read Creek Örbäcken SFR seglist file ###\n",
    "sl_sfr = read_segfile(file=\"sfr_segfile.dat\", protocol=table)\n",
    "\n",
    "\n",
    "### Create clist with sl_sfr as its base ###\n",
    "cl_sfr_pp = create_clist_from_seglist(seglist=sl_sfr, linkage_type=endpoints, dist_thresh=5.0)\n",
    "\n",
    "\n",
    "### Instruct PLPROC to read the draincond.dat  ###\n",
    "### list file to obtain conductance values at  ###\n",
    "### pilot points by inserting the following    ###\n",
    "### function into the PLPROC script.           ###\n",
    "read_list_file(reference_clist='cl_sfr_pp', file='sfr_cond.dat', plist='pp_sfr_cond';column=2)\n",
    "\n",
    "\n",
    "### Instruct PLPROC to build an SLIST of model ###\n",
    "### drain cells to which interpolation must    ###\n",
    "### take place                                 ###\n",
    "\n",
    "\n",
    "sfr_cells = cl_mf.find_cells_in_lists(file={ml_name}.sfr_packagedata.txt, &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl}, list_col_start=2, keytext_start='top_of_file', &\n",
    "    keytext_end='end_of_file')\n",
    "\n",
    "\n",
    "sfr_cond=new_plist(reference_clist=cl_mf,value=0.0)\n",
    "\n",
    "\n",
    "sfr_cond=pp_sfr_cond.interp_using_file(file=factors_sfr_cells.dat, transform=log)\n",
    "\n",
    "\n",
    "replace_cells_in_lists(                            &\n",
    "    old_file={ml_name}.sfr_packagedata.txt,        &\n",
    "    new_file=new_{ml_name}.sfr_packagedata.txt,    &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl},       &\n",
    "    list_col_start=2,                              &\n",
    "    keytext_start='top_of_file',                   &\n",
    "    keytext_end='bottom_of_file',                  &\n",
    "    plist=sfr_cond;column=9;action='replace'    &\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "###### --- GHB SEGLISTS\n",
    "\n",
    "sl_ghb_red = read_segfile(file=\"ghb_red_segfile.dat\", protocol=table)\n",
    "sl_ghb_orange = read_segfile(file=\"ghb_orange_segfile.dat\", protocol=table)\n",
    "sl_ghb_yellow = read_segfile(file=\"ghb_yellow_segfile.dat\", protocol=table)\n",
    "sl_ghb_limegreen = read_segfile(file=\"ghb_limegreen_segfile.dat\", protocol=table)\n",
    "sl_ghb_royalblue = read_segfile(file=\"ghb_royalblue_segfile.dat\", protocol=table)\n",
    "sl_ghb_blueviolet = read_segfile(file=\"ghb_blueviolet_segfile.dat\", protocol=table)\n",
    "sl_ghb_magenta = read_segfile(file=\"ghb_magenta_segfile.dat\", protocol=table)\n",
    "\n",
    "cl_ghb_red_pp = create_clist_from_seglist(seglist=sl_ghb_red, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_orange_pp = create_clist_from_seglist(seglist=sl_ghb_orange, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_yellow_pp = create_clist_from_seglist(seglist=sl_ghb_yellow, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_limegreen_pp = create_clist_from_seglist(seglist=sl_ghb_limegreen, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_royalblue_pp = create_clist_from_seglist(seglist=sl_ghb_royalblue, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_blueviolet_pp = create_clist_from_seglist(seglist=sl_ghb_blueviolet, linkage_type=endpoints, dist_thresh=5.0)\n",
    "cl_ghb_magenta_pp = create_clist_from_seglist(seglist=sl_ghb_magenta, linkage_type=endpoints, dist_thresh=5.0)\n",
    "\n",
    "read_list_file(reference_clist='cl_ghb_red_pp', file='ghb_red_cond.dat', plist='pp_ghb_red_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_orange_pp', file='ghb_orange_cond.dat', plist='pp_ghb_orange_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_yellow_pp', file='ghb_yellow_cond.dat', plist='pp_ghb_yellow_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_limegreen_pp', file='ghb_limegreen_cond.dat', plist='pp_ghb_limegreen_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_royalblue_pp', file='ghb_royalblue_cond.dat', plist='pp_ghb_royalblue_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_blueviolet_pp', file='ghb_blueviolet_cond.dat', plist='pp_ghb_blueviolet_c';column=2)\n",
    "read_list_file(reference_clist='cl_ghb_magenta_pp', file='ghb_magenta_cond.dat', plist='pp_ghb_magenta_c';column=2)\n",
    "\n",
    "ghb_red_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl}, list_col_start=1, keytext_start='top_of_file', &\n",
    "    keytext_end='2387  ghb_orange')\n",
    "\n",
    "ghb_orange_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl}, list_col_start=1, keytext_start='2387  ghb_red', &\n",
    "    keytext_end='2792  ghb_yellow')\n",
    "    \n",
    "ghb_yellow_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl}, list_col_start=1, keytext_start='2800  ghb_orange', &\n",
    "    keytext_end='2802  ghb_limegreen')\n",
    "\n",
    "ghb_limegreen_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl}, list_col_start=1, keytext_start='3090  ghb_yellow', &\n",
    "    keytext_end='1  ghb_royalblue')\n",
    "\n",
    "ghb_royalblue_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl}, list_col_start=1, keytext_start='3057  ghb_limegreen', &\n",
    "    keytext_end='1  ghb_blueviolet')\n",
    "\n",
    "ghb_blueviolet_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl}, list_col_start=1, keytext_start='2802  ghb_royalblue', &\n",
    "    keytext_end='316  ghb_magenta')\n",
    "\n",
    "ghb_magenta_cells = cl_mf.find_cells_in_lists(file={ml_name}.ghb_stress_period_data_1.txt, &\n",
    "    model_type=undefined;nlay=1;ncpl={ncpl}, list_col_start=1, keytext_start='316  ghb_blueviolet', &\n",
    "    keytext_end='end_of_file')\n",
    "\n",
    "\n",
    "ghb_cond=new_plist(reference_clist=cl_mf,value=0.0)\n",
    "\n",
    "\n",
    "## --- GHB Red\n",
    "ghb_cond=pp_ghb_red_c.interp_using_file(file=factors_ghb_red_cells.dat, transform=log)\n",
    "\n",
    "replace_cells_in_lists(old_file={ml_name}.ghb_stress_period_data_1.txt,                                &\n",
    "    new_file=partial1_{ml_name}.ghb_stress_period_data_1.txt, model_type=undefined;nlay=1;ncpl={ncpl}, &\n",
    "    list_col_start=1, keytext_start='top_of_file', keytext_end='2387  ghb_orange',                     &\n",
    "    plist=ghb_cond;column=4;action='replace')\n",
    "\n",
    "\n",
    "## --- GHB Orange\n",
    "ghb_cond=pp_ghb_orange_c.interp_using_file(file=factors_ghb_orange_cells.dat, transform=log)\n",
    "\n",
    "replace_cells_in_lists(old_file=partial1_{ml_name}.ghb_stress_period_data_1.txt,                       &\n",
    "    new_file=partial2_{ml_name}.ghb_stress_period_data_1.txt, model_type=undefined;nlay=1;ncpl={ncpl}, &\n",
    "    list_col_start=1, keytext_start='2387  ghb_red', keytext_end='2792  ghb_yellow',                   &\n",
    "    plist=ghb_cond;column=4;action='replace')\n",
    "\n",
    "\n",
    "## --- GHB Yellow\n",
    "ghb_cond=pp_ghb_yellow_c.interp_using_file(file=factors_ghb_yellow_cells.dat, transform=log)\n",
    "\n",
    "replace_cells_in_lists(old_file=partial2_{ml_name}.ghb_stress_period_data_1.txt,                       &\n",
    "    new_file=partial3_{ml_name}.ghb_stress_period_data_1.txt, model_type=undefined;nlay=1;ncpl={ncpl}, &\n",
    "    list_col_start=1, keytext_start='2800  ghb_orange', keytext_end='2802  ghb_limegreen',             &\n",
    "    plist=ghb_cond;column=4;action='replace')\n",
    "\n",
    "\n",
    "## --- GHB Limegreen\n",
    "ghb_cond=pp_ghb_limegreen_c.interp_using_file(file=factors_ghb_limegreen_cells.dat, transform=log)\n",
    "\n",
    "replace_cells_in_lists(old_file=partial3_{ml_name}.ghb_stress_period_data_1.txt,                       &\n",
    "    new_file=partial4_{ml_name}.ghb_stress_period_data_1.txt, model_type=undefined;nlay=1;ncpl={ncpl}, &\n",
    "    list_col_start=1, keytext_start='3090  ghb_yellow', keytext_end='1  ghb_royalblue',                &\n",
    "    plist=ghb_cond;column=4;action='replace')\n",
    "\n",
    "\n",
    "## --- GHB Royalblue\n",
    "ghb_cond=pp_ghb_royalblue_c.interp_using_file(file=factors_ghb_royalblue_cells.dat, transform=log)\n",
    "\n",
    "replace_cells_in_lists(old_file=partial4_{ml_name}.ghb_stress_period_data_1.txt,                       &\n",
    "    new_file=partial5_{ml_name}.ghb_stress_period_data_1.txt, model_type=undefined;nlay=1;ncpl={ncpl}, &\n",
    "    list_col_start=1, keytext_start='3057  ghb_limegreen', keytext_end='1  ghb_blueviolet',            &\n",
    "    plist=ghb_cond;column=4;action='replace')\n",
    "\n",
    "\n",
    "## --- GHB Blueviolet\n",
    "ghb_cond=pp_ghb_blueviolet_c.interp_using_file(file=factors_ghb_blueviolet_cells.dat, transform=log)\n",
    "\n",
    "replace_cells_in_lists(old_file=partial5_{ml_name}.ghb_stress_period_data_1.txt,                       &\n",
    "    new_file=partial6_{ml_name}.ghb_stress_period_data_1.txt, model_type=undefined;nlay=1;ncpl={ncpl}, &\n",
    "    list_col_start=1, keytext_start='2802  ghb_royalblue', keytext_end='316  ghb_magenta',             &\n",
    "    plist=ghb_cond;column=4;action='replace')\n",
    "\n",
    "\n",
    "## --- GHB Magenta\n",
    "ghb_cond=pp_ghb_magenta_c.interp_using_file(file=factors_ghb_magenta_cells.dat, transform=log)\n",
    "\n",
    "replace_cells_in_lists(old_file=partial6_{ml_name}.ghb_stress_period_data_1.txt,                       &\n",
    "    new_file=new_{ml_name}.ghb_stress_period_data_1.txt, model_type=undefined;nlay=1;ncpl={ncpl},      &\n",
    "    list_col_start=1, keytext_start='316  ghb_blueviolet', keytext_end='end_of_file',                  &\n",
    "    plist=ghb_cond;column=4;action='replace')\n",
    "\n",
    "### Write reports ###\n",
    "report_all_entities(file=report1.dat)\n",
    "cl_mf.report_dependent_lists(file='report2.dat')\n",
    "#cl_sfrpp.report_dependent_lists(file='report3.dat')\n",
    "'''\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run PLPROC\n",
    "run.run_process(\n",
    "    'plproc',\n",
    "    path=tmp_model_ws,\n",
    "    commands=['plproc1.dat']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew... is the parameterization complete? I think so (at least up until transport parameters)...\n",
    "\n",
    "The workspace is a bit of a mess, so let's clean up non pertinent files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(tmp_model_ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_files = [i for i in os.listdir(tmp_model_ws) if 'temp' in i or 'partial' in i or 'report' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in rm_files:\n",
    "    os.remove(os.path.join(tmp_model_ws, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(tmp_model_ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's left? ... make MF read the new SFR and GHB files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file\n",
    "with open(os.path.join(tmp_model_ws, f'{ml_name}.ghb'), 'r') as file :\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace(f'{ml_name}.ghb_stress_period_data_1.txt', f'new_{ml_name}.ghb_stress_period_data_1.txt')\n",
    "\n",
    "# Write the file out again\n",
    "with open(os.path.join(tmp_model_ws, f'{ml_name}.ghb'), 'w') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file\n",
    "with open(os.path.join(tmp_model_ws, f'{ml_name}.sfr'), 'r') as file :\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace(f'{ml_name}.sfr_packagedata.txt', f'new_{ml_name}.sfr_packagedata.txt')\n",
    "\n",
    "# Write the file out again\n",
    "with open(os.path.join(tmp_model_ws, f'{ml_name}.sfr'), 'w') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.get_model().npf.k.plot(colorbar=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.get_model().npf.k33.plot(colorbar=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.get_model().sto.sy.plot(colorbar=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.get_model().sto.ss.plot(colorbar=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "\n",
    "write_plproc_script(os.path.join(tmp_model_ws, 'plproc1.dat'), [\n",
    "'''\n",
    "### Read model grid ###\n",
    "cl_mf = read_mf6_grid_specs(file=experimental.disv.grb,    &\n",
    "                            dimensions=3,                  &\n",
    "                            slist_idomain = idomain,       &\n",
    "                            slist_layernum = layer,        &\n",
    "                            plist_bottom = bottom) # Is bottom needed?\n",
    "\n",
    "### Read pilot-points file ###\n",
    "cl_pp = read_list_file(file=pp3d_coarse.dat,               &\n",
    "                       id_type=character,                  &\n",
    "                       dimensions=3,                       &\n",
    "                       slist=zone; col=5,                  &\n",
    "                       slist=lyr; col=7,                   &\n",
    "                       plist=kh_pp; col=8,                 &\n",
    "                       plist=kv_pp; col=9,                 &\n",
    "                       plist=sy_pp; col=10,                &\n",
    "                       plist=ss_pp; col=11)\n",
    "\n",
    "\n",
    "### Create CLIST partitions so that the function \"write_model_input_file\" writes ###\n",
    "### a MODFLOW readable parameter file with the same length as                    ### \n",
    "### experimental.npf_k_layer1.txt                                                ###\n",
    "### Is this the proper way to go about it?                                       ###\n",
    "cl_mf_layer1 = cl_mf.partition_by_eqn(select=(layer==1))\n",
    "cl_mf_layer2 = cl_mf.partition_by_eqn(select=(layer==2))\n",
    "cl_mf_layer3 = cl_mf.partition_by_eqn(select=(layer==3))\n",
    "\n",
    "\n",
    "### Calculate kriging factors for each CLIST partition ###\n",
    "### If creating partitions is wrong, then this will be ###\n",
    "### wrong as well...                                   ###\n",
    "calc_kriging_factors_3d(target_clist=cl_mf_layer1,                   &\n",
    "                        source_clist=cl_pp,                          &\n",
    "                        file=ppfactors1.dat,                         &\n",
    "                        variogram=exponential,                       &\n",
    "                        a_hmax=32, a_hmin=28, a_vert=8,              &\n",
    "                        ang1=60, ang2=20, ang3=0,                    &\n",
    "                        kriging=ordinary,                            &\n",
    "                        search_rad_max_hdir=130,                     &\n",
    "                        search_rad_min_hdir=66,                      &\n",
    "                        search_rad_vert=33,                          &\n",
    "                        min_points=1,max_points=10)\n",
    "\n",
    "calc_kriging_factors_3d(target_clist=cl_mf_layer2,                   &\n",
    "                        source_clist=cl_pp,                          &\n",
    "                        file=ppfactors2.dat,                         &\n",
    "                        variogram=exponential,                       &\n",
    "                        a_hmax=32, a_hmin=28, a_vert=8,              &\n",
    "                        ang1=60, ang2=20, ang3=0,                    &\n",
    "                        kriging=ordinary,                            &\n",
    "                        search_rad_max_hdir=130,                     &\n",
    "                        search_rad_min_hdir=66,                      &\n",
    "                        search_rad_vert=33,                          &\n",
    "                        min_points=1,max_points=10)\n",
    "\n",
    "calc_kriging_factors_3d(target_clist=cl_mf_layer3,                   &\n",
    "                        source_clist=cl_pp,                          &\n",
    "                        file=ppfactors3.dat,                         &\n",
    "                        variogram=exponential,                       &\n",
    "                        a_hmax=32, a_hmin=28, a_vert=8,              &\n",
    "                        ang1=60, ang2=20, ang3=0,                    &\n",
    "                        kriging=ordinary,                            &\n",
    "                        search_rad_max_hdir=130,                     &\n",
    "                        search_rad_min_hdir=66,                      &\n",
    "                        search_rad_vert=33,                          &\n",
    "                        min_points=1,max_points=10)\n",
    "\n",
    "### Write  ###\n",
    "prop_mf_l1=new_plist(reference_clist=cl_mf_layer1, value=1.0)\n",
    "prop_mf_l2=new_plist(reference_clist=cl_mf_layer2, value=1.0)\n",
    "prop_mf_l3=new_plist(reference_clist=cl_mf_layer3, value=1.0)\n",
    "\n",
    "### Write kh layer 1 ###\n",
    "prop_mf_l1=86.4\n",
    "prop_mf_l1=kh_pp.krige_using_file(file='ppfactors1.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array_l1.tpl, model_input_file=experimental.npf_k_layer1.txt)\n",
    "\n",
    "### Write kh layer 2 ###\n",
    "prop_mf_l2=1.0E-2\n",
    "prop_mf_l2=kh_pp.krige_using_file(file='ppfactors2.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array_l2.tpl, model_input_file=experimental.npf_k_layer2.txt)\n",
    "\n",
    "### Write kh layer 3 ###\n",
    "prop_mf_l3=63.2\n",
    "prop_mf_l3=kh_pp.krige_using_file(file='ppfactors3.dat',transform='log')\n",
    "write_model_input_file(template_file=gen_mf_array_l3.tpl, model_input_file=experimental.npf_k_layer3.txt)\n",
    "\n",
    "### Write reports ###\n",
    "report_all_entities(file=report1.dat)\n",
    "cl_mf.report_dependent_lists(file='report2.dat')\n",
    "'''\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
